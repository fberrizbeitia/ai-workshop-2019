[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/fberrizbeitia/ai-workshop-2019/master?filepath=Biased%20Predictive%20Model%20Generation%20Exercise.ipynb)


## Text mining as an example of biased predictive modeling
In this notebook, we will go thru the basics of text mining and produce a purposely-biased predictive model using machine-learning techniques.

For this exercise, we will try to classify hotel reviews into three categories: negative, neutral and positive. Our dataset is segregated by gender: there is female-only dataset and a male-only one. To illustrate how biases can be introduced into a model. We will train our model using the male-only dataset and then test it using female only data. The discrepancy on the overall accuracy will show how a biased sample can compromise the performance and the fairness of the model.

To launch the noteboock [click here](https://mybinder.org/v2/gh/fberrizbeitia/ai-workshop-2019/master?filepath=Biased%20Predictive%20Model%20Generation%20Exercise.ipynb) 
